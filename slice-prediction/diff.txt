diff --git a/slice-prediction/diff.txt b/slice-prediction/diff.txt
index 41d91b0..e69de29 100644
--- a/slice-prediction/diff.txt
+++ b/slice-prediction/diff.txt
@@ -1,511 +0,0 @@
-diff --git a/slice-prediction/evaluate.py b/slice-prediction/evaluate.py
-index 8b7f652..07c2edb 100644
---- a/slice-prediction/evaluate.py
-+++ b/slice-prediction/evaluate.py
-@@ -273,7 +273,7 @@ def evaluate_model(model, data_loader, device, output_dir, save_wavelets=False):
-                     # Save first sample in batch
-                     sample_idx = 0
-                     
--                    # Save coefficients as .npy files
-+                    # Save coefficients as .npy files (keep batch-named files for backward compatibility)
-                     np.save(
-                         wavelet_dir / f'batch{batch_idx}_input_wavelets.npy',
-                         input_wavelets[sample_idx].cpu().numpy()
-@@ -286,23 +286,66 @@ def evaluate_model(model, data_loader, device, output_dir, save_wavelets=False):
-                         wavelet_dir / f'batch{batch_idx}_target_wavelets.npy',
-                         target_wavelets[sample_idx].cpu().numpy()
-                     )
--                    
-+
-+                    # Also save patient-specific coefficient files when patient_id is available
-+                    try:
-+                        sample_slice_info = slice_indices[sample_idx]
-+                        if isinstance(sample_slice_info, (list, tuple)):
-+                            sample_patient_id = str(sample_slice_info[1])
-+                        else:
-+                            try:
-+                                _slice = int(sample_slice_info.item())
-+                                sample_patient_id = f"batch{batch_idx}_sample{sample_idx}_slice{_slice}"
-+                            except Exception:
-+                                sample_patient_id = f"batch{batch_idx}_sample{sample_idx}"
-+                    except Exception:
-+                        sample_patient_id = f"batch{batch_idx}_sample{sample_idx}"
-+
-+                    np.save(
-+                        wavelet_dir / f'batch{batch_idx}_input_wavelets_{sample_patient_id}.npy',
-+                        input_wavelets[sample_idx].cpu().numpy()
-+                    )
-+                    np.save(
-+                        wavelet_dir / f'batch{batch_idx}_output_wavelets_{sample_patient_id}.npy',
-+                        output_wavelets[sample_idx].cpu().numpy()
-+                    )
-+                    np.save(
-+                        wavelet_dir / f'batch{batch_idx}_target_wavelets_{sample_patient_id}.npy',
-+                        target_wavelets[sample_idx].cpu().numpy()
-+                    )
-+
-                     # Create visualizations - NOW SHOWING ALL INPUT COMPONENTS
-+                    # Save both batch-named and patient-specific visualizations
-                     visualize_wavelet_decomposition(
-                         input_wavelets[sample_idx],
-                         f'Input Wavelet Decomposition (Batch {batch_idx}) - ALL 8 Channels',
-                         wavelet_viz_dir / f'batch{batch_idx}_input_wavelets_ALL8.png'
-                     )
-+                    visualize_wavelet_decomposition(
-+                        input_wavelets[sample_idx],
-+                        f'Input Wavelet Decomposition - {sample_patient_id} - ALL 8 Channels',
-+                        wavelet_viz_dir / f'batch{batch_idx}_input_wavelets_ALL8_{sample_patient_id}.png'
-+                    )
-                     visualize_wavelet_decomposition(
-                         output_wavelets[sample_idx],
-                         f'Output Wavelet Decomposition (Batch {batch_idx})',
-                         wavelet_viz_dir / f'batch{batch_idx}_output_wavelets.png'
-                     )
-+                    visualize_wavelet_decomposition(
-+                        output_wavelets[sample_idx],
-+                        f'Output Wavelet Decomposition - {sample_patient_id}',
-+                        wavelet_viz_dir / f'batch{batch_idx}_output_wavelets_{sample_patient_id}.png'
-+                    )
-                     visualize_wavelet_decomposition(
-                         target_wavelets[sample_idx],
-                         f'Target Wavelet Decomposition (Batch {batch_idx})',
-                         wavelet_viz_dir / f'batch{batch_idx}_target_wavelets.png'
-                     )
-+                    visualize_wavelet_decomposition(
-+                        target_wavelets[sample_idx],
-+                        f'Target Wavelet Decomposition - {sample_patient_id}',
-+                        wavelet_viz_dir / f'batch{batch_idx}_target_wavelets_{sample_patient_id}.png'
-+                    )
-             
-             # Time metric calculation
-             metric_start = perf_counter()
-@@ -311,7 +354,20 @@ def evaluate_model(model, data_loader, device, output_dir, save_wavelets=False):
-             batch_size = inputs.shape[0]
-             for i in range(batch_size):
-                 metrics = calculate_metrics(outputs[i], targets[i])
--                metrics['slice_idx'] = slice_indices[i].item()
-+                # Robustly extract slice index and optional patient identifier
-+                slice_info = slice_indices[i]
-+                if isinstance(slice_info, (list, tuple)):
-+                    slice_idx = int(slice_info[0])
-+                    patient_id = str(slice_info[1])
-+                else:
-+                    try:
-+                        slice_idx = int(slice_info.item())
-+                    except Exception:
-+                        slice_idx = int(slice_info)
-+                    patient_id = f"batch{batch_idx}_sample{i}_slice{slice_idx}"
-+
-+                metrics['slice_idx'] = slice_idx
-+                metrics['patient_id'] = patient_id
-                 metrics['batch_idx'] = batch_idx
-                 all_metrics.append(metrics)
-                 
-@@ -322,12 +378,30 @@ def evaluate_model(model, data_loader, device, output_dir, save_wavelets=False):
-                 
-                 # Optionally save predictions
-                 if batch_idx < 10:  # Save first 10 batches for inspection
--                    pred_path = predictions_dir / f'batch{batch_idx}_sample{i}.npy'
-+                    # Use patient_id when available to make filenames deterministic
-+                    try:
-+                        pid_for_file = patient_id
-+                    except Exception:
-+                        # Fallback to a batch/sample based id
-+                        pid_for_file = f"batch{batch_idx}_sample{i}"
-+                    pred_path = predictions_dir / f'batch{batch_idx}_sample{i}_{pid_for_file}.npy'
-                     np.save(pred_path, outputs[i].cpu().numpy())
-                 
--                # Log first sample to wandb
-+                # Log first sample to wandb - SAVE ALL COMPONENTS FOR SAME SAMPLE
-                 if batch_idx == 0 and i == 0 and not sample_logged:
--                    # Create comparison visualization - FIXED labels
-+                    # Use propagated patient_id when available
-+                    slice_info = slice_indices[i]
-+                    if isinstance(slice_info, (list, tuple)):
-+                        slice_idx = int(slice_info[0])
-+                        patient_id = str(slice_info[1])
-+                    else:
-+                        try:
-+                            slice_idx = int(slice_info.item())
-+                        except Exception:
-+                            slice_idx = int(slice_info)
-+                        patient_id = f"batch{batch_idx}_sample{i}_slice{slice_idx}"
-+                    
-+                    # Create comparison visualization (inputs Z-1, Z+1, prediction, target, error)
-                     fig, axes = plt.subplots(4, 5, figsize=(15, 12))
-                     modalities = ['T1n', 'T1c', 'T2w', 'T2f']
-                     
-@@ -358,15 +432,67 @@ def evaluate_model(model, data_loader, device, output_dir, save_wavelets=False):
-                         axes[mod_idx, 4].set_title(f'|Error|' if mod_idx == 0 else '')
-                         axes[mod_idx, 4].axis('off')
-                     
--                    plt.suptitle(f'Sample Prediction (Slice {slice_indices[i].item()})')
-+                    plt.suptitle(f'Sample Prediction - {patient_id}')
-                     plt.tight_layout()
-                     
--                    # Save and log to wandb
--                    sample_path = predictions_dir / 'sample_prediction.png'
--                    plt.savefig(sample_path, dpi=150, bbox_inches='tight')
--                    wandb.log({"eval/sample_prediction": wandb.Image(str(sample_path))})
-+                    # Save reconstruction with patient ID in filename
-+                    reconstruction_path = predictions_dir / f'reconstruction_{patient_id}.png'
-+                    plt.savefig(reconstruction_path, dpi=150, bbox_inches='tight')
-+                    wandb.log({f"eval/reconstruction_{patient_id}": wandb.Image(str(reconstruction_path))})
-                     plt.close()
-                     
-+                    # Save raw tensor data for this specific sample
-+                    sample_data_path = predictions_dir / f'sample_data_{patient_id}.npz'
-+                    np.savez(sample_data_path,
-+                        input=inputs[i].cpu().numpy(),
-+                        target=targets[i].cpu().numpy(), 
-+                        output=outputs[i].cpu().numpy(),
-+                        slice_idx=slice_idx,
-+                        batch_idx=batch_idx,
-+                        patient_id=patient_id
-+                    )
-+                    
-+                    # Save wavelets for the SAME sample (if model has wavelets)
-+                    if hasattr(model, 'dwt2d_batch'):
-+                        input_wavelets = model.dwt2d_batch(inputs[i:i+1])   # Keep batch dim
-+                        output_wavelets = model.dwt2d_batch(outputs[i:i+1])
-+                        target_wavelets = model.dwt2d_batch(targets[i:i+1])
-+                        
-+                        # Save wavelet coefficient tensors
-+                        wavelet_data_path = predictions_dir / f'wavelets_{patient_id}.npz'
-+                        np.savez(wavelet_data_path,
-+                            input_wavelets=input_wavelets[0].cpu().numpy(),
-+                            output_wavelets=output_wavelets[0].cpu().numpy(),
-+                            target_wavelets=target_wavelets[0].cpu().numpy()
-+                        )
-+                        
-+                        # Create and save wavelet visualizations with matching filename
-+                        # Input wavelets (all 8 channels)
-+                        visualize_wavelet_decomposition(
-+                            input_wavelets[0], 
-+                            f'Input Wavelets - {patient_id}', 
-+                            output_path=predictions_dir / f'wavelets_input_{patient_id}.png'
-+                        )
-+                        wandb.log({f"eval/wavelets_input_{patient_id}": wandb.Image(str(predictions_dir / f'wavelets_input_{patient_id}.png'))})
-+                        
-+                        # Output wavelets 
-+                        visualize_wavelet_decomposition(
-+                            output_wavelets[0],
-+                            f'Output Wavelets - {patient_id}',
-+                            output_path=predictions_dir / f'wavelets_output_{patient_id}.png'
-+                        )
-+                        wandb.log({f"eval/wavelets_output_{patient_id}": wandb.Image(str(predictions_dir / f'wavelets_output_{patient_id}.png'))})
-+                        
-+                        # Target wavelets
-+                        visualize_wavelet_decomposition(
-+                            target_wavelets[0], 
-+                            f'Target Wavelets - {patient_id}',
-+                            output_path=predictions_dir / f'wavelets_target_{patient_id}.png'  
-+                        )
-+                        wandb.log({f"eval/wavelets_target_{patient_id}": wandb.Image(str(predictions_dir / f'wavelets_target_{patient_id}.png'))})
-+                        
-+                        print(f"✓ Saved complete sample data and wavelets for {patient_id}")
-+                    
-                     sample_logged = True
-             
-             metric_time = perf_counter() - metric_start
-@@ -581,13 +707,13 @@ def run_evaluation(model, data_loader, device, output_dir, model_type, wavelet_n
-     # Log example wavelet visualizations to wandb
-     if save_wavelets:
-         wavelet_viz_dir = Path(output_dir) / 'wavelet_visualizations'
--        # Log ALL input wavelet visualizations (showing Z-1 and Z+1 components)
--        for img_path in sorted(wavelet_viz_dir.glob('batch0_input_wavelets_ALL8.png')):
-+        # Log input wavelet visualizations (match any patient-specific file)
-+        for img_path in sorted(wavelet_viz_dir.glob('*input_wavelets_ALL8*.png')):
-             wandb.log({f"wavelets/{img_path.stem}": wandb.Image(str(img_path))})
--        # Log output and target wavelets
--        for img_path in sorted(wavelet_viz_dir.glob('batch0_*output_wavelets.png'))[:3]:
-+        # Log output and target wavelets (patient-specific or batch-named)
-+        for img_path in sorted(wavelet_viz_dir.glob('*output_wavelets*.png'))[:6]:
-             wandb.log({f"wavelets/{img_path.stem}": wandb.Image(str(img_path))})
--        for img_path in sorted(wavelet_viz_dir.glob('batch0_*target_wavelets.png'))[:3]:
-+        for img_path in sorted(wavelet_viz_dir.glob('*target_wavelets*.png'))[:6]:
-             wandb.log({f"wavelets/{img_path.stem}": wandb.Image(str(img_path))})
-     
-     # Save results to CSV
-diff --git a/slice-prediction/ex_job.yml b/slice-prediction/ex_job.yml
-index 1da2a26..ec51ed4 100644
---- a/slice-prediction/ex_job.yml
-+++ b/slice-prediction/ex_job.yml
-@@ -74,7 +74,7 @@ spec:
- 
-             echo "=== Starting WandB Sweep Agent ==="
-             # Run WandB sweep agent (trials will read from ./preprocessed_slices and ./preprocessed_slices_val)
--            wandb agent timgsereda/wavelet-brats-synthesis-slice-prediction/zfqabz0s
-+            wandb agent timgsereda/wavelet-brats-synthesis-slice-prediction/j9wznyhd
- 
-         env:
-         - name: WANDB_API_KEY
-diff --git a/slice-prediction/generate_figure2.py b/slice-prediction/generate_figure2.py
-index e7c0bbf..e59a450 100644
---- a/slice-prediction/generate_figure2.py
-+++ b/slice-prediction/generate_figure2.py
-@@ -38,7 +38,17 @@ def select_best_example(data_loader, model, device, num_candidates=50):
-             input_sample = inputs[0].cpu()
-             target_sample = targets[0].cpu()
-             output_sample = outputs[0].cpu()
--            slice_idx = slice_indices[0].item()
-+            # Robust extraction in case dataset returns (slice_idx, patient_id)
-+            first_info = slice_indices[0]
-+            patient_id = None
-+            if isinstance(first_info, (list, tuple)):
-+                slice_idx = int(first_info[0])
-+                patient_id = str(first_info[1])
-+            else:
-+                try:
-+                    slice_idx = int(first_info.item())
-+                except Exception:
-+                    slice_idx = int(first_info)
-             
-             # Calculate MSE
-             mse = torch.mean((output_sample - target_sample) ** 2).item()
-@@ -52,6 +62,7 @@ def select_best_example(data_loader, model, device, num_candidates=50):
-                     'target': target_sample,
-                     'output': output_sample,
-                     'slice_idx': slice_idx,
-+                    'patient_id': patient_id,
-                     'mse': mse,
-                     'batch_idx': i
-                 })
-@@ -304,6 +315,17 @@ def main():
-     # Create output directory
-     output_path = Path(args.output)
-     output_path.parent.mkdir(parents=True, exist_ok=True)
-+
-+    # If we selected an example and it contains a patient_id, append it to the filename
-+    try:
-+        pid = examples.get('swin', {}).get('patient_id', None)
-+        if pid:
-+            # Only append when the filename doesn't already contain the id
-+            stem = output_path.stem
-+            if str(pid) not in stem:
-+                output_path = output_path.with_name(f"{stem}_{pid}" + output_path.suffix)
-+    except Exception:
-+        pass
-     
-     # Generate figure
-     if args.simple or len(examples) == 1:
-diff --git a/slice-prediction/logging_utils.py b/slice-prediction/logging_utils.py
-index 141a2f6..be621fc 100644
---- a/slice-prediction/logging_utils.py
-+++ b/slice-prediction/logging_utils.py
-@@ -1,14 +1,15 @@
- import numpy as np
- import cv2
- import torch
--from typing import List
-+from typing import List, Optional
- 
- def create_reconstruction_log_panel(
-     inputs_sample: torch.Tensor,      # Model input (Prev/Next slices), shape [8, H, W]
-     target_sample: torch.Tensor,      # Ground Truth (Real middle slice), shape [4, H, W]
-     output_sample: torch.Tensor,      # Model Prediction (Reconstructed middle slice), shape [4, H, W]
-     slice_idx: int,
--    batch_idx: int
-+    batch_idx: int,
-+    patient_id: Optional[str] = None
- ) -> np.ndarray:
-     modalities = ["t1", "t1ce", "t2", "flair"]
-     all_rows = []
-@@ -59,6 +60,8 @@ def create_reconstruction_log_panel(
-     final_panel = np.vstack(all_rows)
-     main_header = np.full((40, final_panel.shape[1], 3), 60, dtype=np.uint8)
-     title = f"Slice Reconstruction - Batch #{batch_idx}, Middle Slice #{slice_idx}"
-+    if patient_id is not None:
-+        title = f"{title} | {patient_id}"
-     cv2.putText(main_header, title, (10, 28), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 1, cv2.LINE_AA)
-     
-     return np.vstack([main_header, final_panel])
-\ No newline at end of file
-diff --git a/slice-prediction/train.py b/slice-prediction/train.py
-index b356db4..d3d8616 100644
---- a/slice-prediction/train.py
-+++ b/slice-prediction/train.py
-@@ -12,6 +12,7 @@ from collections import OrderedDict
- from threading import Lock
- import argparse
- from time import time, perf_counter
-+from pathlib import Path
- import torch.multiprocessing
- import cv2
- import wandb
-@@ -185,6 +186,9 @@ class BraTS2D5Dataset(Dataset):
-                     raise FileNotFoundError(f"No segmentation file found in {patient_name}")
-                 patient_files['label'] = seg_matches[0]
- 
-+                # Preserve original patient identifier (folder basename)
-+                # so callers can save artifacts using the original dataset numbering.
-+                patient_files['_patient_id'] = patient_name
-                 # Validate files for obvious corruption (gzip integrity and non-zero size)
-                 is_valid, error_msg = self._validate_patient_files(patient_files, patient_name)
-                 if is_valid:
-@@ -324,7 +328,9 @@ class BraTS2D5Dataset(Dataset):
-                         continue
-                     brain_slice = proc['t1c'][0, :, :, slice_idx]
-                     if torch.mean(brain_slice) > 50.0:
--                        self.slice_map.append((i, slice_idx))
-+                        # Store patient id alongside volume and slice index
-+                        patient_id = patient_files.get('_patient_id', f'patient_{i}')
-+                        self.slice_map.append((i, slice_idx, patient_id))
- 
-                 del proc
- 
-@@ -427,7 +433,8 @@ class BraTS2D5Dataset(Dataset):
- 
-     def __getitem__(self, index):
-         start = perf_counter()
--        volume_idx, slice_idx = self.slice_map[index]
-+        # slice_map entries are (volume_idx, slice_idx, patient_id)
-+        volume_idx, slice_idx, patient_id = self.slice_map[index]
-         patient_data = self._get_volume(volume_idx)
- 
-         img_modalities = torch.cat([patient_data['t1n'], patient_data['t1c'],
-@@ -453,7 +460,7 @@ class BraTS2D5Dataset(Dataset):
-             input_tensor = torch.cat([prev_slice, next_slice], dim=0)
-             elapsed = perf_counter() - start
-             self._record_getitem_time(elapsed)
--            return input_tensor, target_tensor, slice_idx
-+            return input_tensor, target_tensor, (int(slice_idx), patient_id)
- 
-         except IndexError as e:
-             # Fallback: log and use middle slice of volume
-@@ -473,7 +480,7 @@ class BraTS2D5Dataset(Dataset):
-             elapsed = perf_counter() - start
-             self._record_getitem_time(elapsed)
-             print(f"Using fallback middle slice: {middle_slice}")
--            return input_tensor, target_tensor, middle_slice
-+            return input_tensor, target_tensor, (int(middle_slice), patient_id if 'patient_id' in locals() else f'patient_{volume_idx}')
- 
- 
- class SimpleCSVTripletDataset(Dataset):
-@@ -601,7 +608,17 @@ class SimpleCSVTripletDataset(Dataset):
-                     pass
-                 # Return the first successfully loaded sample (may be different from
-                 # the originally requested index if it was corrupted).
--                return input_tensor, target_slice, slice_mid
-+                # Preserve a patient identifier for CSV rows - prefer containing
-+                # directory name, fall back to filename stem.
-+                try:
-+                    patient_dir = os.path.dirname(str(row['t1c']))
-+                    patient_id = os.path.basename(patient_dir) if patient_dir else os.path.basename(str(row['t1c']))
-+                    if not patient_id:
-+                        patient_id = os.path.splitext(os.path.basename(str(row['t1c'])))[0]
-+                except Exception:
-+                    patient_id = f"csvrow_{idx}"
-+
-+                return input_tensor, target_slice, (int(slice_mid), patient_id)
- 
-             except Exception as e:
-                 # Log the corrupted row and file paths, then skip it.
-@@ -1209,7 +1226,7 @@ def main(args):
-                     preview_slices = slice_indices.tolist()[:5]
-                 except Exception:
-                     try:
--                        preview_slices = [ (s[1] if isinstance(s, (list, tuple)) else int(s)) for s in slice_indices[:5] ]
-+                        preview_slices = [ (s[0] if isinstance(s, (list, tuple)) else int(s)) for s in slice_indices[:5] ]
-                     except Exception:
-                         preview_slices = ['N/A']
- 
-@@ -1290,19 +1307,25 @@ def main(args):
-                 
-                 # Create reconstruction visualization
-                 with torch.no_grad():
--                    # Extract first slice index for annotation (robust to collate format)
-+                    # Extract first slice index and patient id for annotation (robust to collate format)
-                     try:
--                        first_slice = slice_indices[0].item()
-+                        first_info = slice_indices[0]
-+                        if isinstance(first_info, (list, tuple)):
-+                            first_slice = int(first_info[0])
-+                            first_patient = str(first_info[1])
-+                        else:
-+                            try:
-+                                first_slice = int(first_info.item())
-+                            except Exception:
-+                                first_slice = int(first_info)
-+                            first_patient = f"batch{i}_sample0_slice{first_slice}"
-                     except Exception:
--                        try:
--                            first_elem = slice_indices[0]
--                            first_slice = first_elem[1] if isinstance(first_elem, (list, tuple)) else int(first_elem)
--                        except Exception:
--                            first_slice = -1
-+                        first_slice = -1
-+                        first_patient = None
- 
-                     panel = create_reconstruction_log_panel(
-                         inputs[0], targets[0], outputs[0], 
--                        first_slice, i
-+                        first_slice, i, patient_id=first_patient
-                     )
-                     wandb.log({"reconstruction_preview": wandb.Image(panel)})
-                 
-@@ -1419,6 +1442,64 @@ def main(args):
-                 # Don't crash training if WandB artifact upload fails; warn and continue
-                 log_warn(f"Failed to log checkpoint artifact to WandB: {e}")
-     
-+    # Save one final sample at end of training for figure generation
-+    try:
-+        print("Saving final training sample for figure generation...")
-+        model.eval()
-+        with torch.no_grad():
-+            # Get one batch
-+            final_batch = next(iter(data_loader))
-+            inputs, targets, slice_indices = final_batch
-+            inputs, targets = inputs.to(device), targets.to(device)
-+            outputs = model(inputs)
-+            
-+            # Use first sample
-+            # Extract slice and patient id robustly from collated slice_indices
-+            try:
-+                first_info = slice_indices[0]
-+                if isinstance(first_info, (list, tuple)):
-+                    final_slice_idx = int(first_info[0])
-+                    final_patient_orig = str(first_info[1])
-+                else:
-+                    try:
-+                        final_slice_idx = int(first_info.item())
-+                    except Exception:
-+                        final_slice_idx = int(first_info)
-+                    final_patient_orig = f"batch0_sample0_slice{final_slice_idx}"
-+            except Exception:
-+                final_slice_idx = -1
-+                final_patient_orig = f"final_epoch{args.epochs}_slice{final_slice_idx}"
-+            final_patient_id = f"final_epoch{args.epochs}_{final_patient_orig}"
-+            
-+            # Save everything for this sample
-+            final_dir = Path(args.output_dir) / "final_sample"
-+            final_dir.mkdir(parents=True, exist_ok=True)
-+            
-+            # Raw data
-+            np.savez(final_dir / f"sample_data_{final_patient_id}.npz",
-+                input=inputs[0].cpu().numpy(),
-+                target=targets[0].cpu().numpy(),
-+                output=outputs[0].cpu().numpy(),
-+                slice_idx=final_slice_idx,
-+                patient_id=final_patient_orig
-+            )
-+            
-+            # Wavelets if available
-+            if hasattr(model, 'dwt2d_batch'):
-+                input_wavelets = model.dwt2d_batch(inputs[0:1])
-+                output_wavelets = model.dwt2d_batch(outputs[0:1]) 
-+                target_wavelets = model.dwt2d_batch(targets[0:1])
-+                
-+                np.savez(final_dir / f"wavelets_{final_patient_id}.npz",
-+                    input_wavelets=input_wavelets[0].cpu().numpy(),
-+                    output_wavelets=output_wavelets[0].cpu().numpy(), 
-+                    target_wavelets=target_wavelets[0].cpu().numpy()
-+                )
-+            
-+            print(f"✓ Final sample saved as {final_patient_id}")
-+    except Exception as e:
-+        print(f"Warning: failed to save final sample: {e}")
-+
-     # Final training timing summary
-     final_timing = timing_stats.get_stats()
-     print(f"\n" + "="*60)
